# Recurrent NN
---
> [!info]+ File Details
> Includes information about this (genus:: Note) from [Year::2]. Contains details on when this was created, what module the note belongs to.
> > *Date :*  14-04-2025
> > *Module :* [[Yr2 NotesðŸ“˜/Semester 1 & 2/ML/Machine Learning]]
> > *Teacher*: 
> > *Resources :*

---
> [!abstract]+ Contents
> List of headings within this topic
> > [[#Speed run]]
> [[#]]
> [[#]]
> [[#]]
> [[#]]

--- 
> [!danger]+ *Speed run*
> Break down of topic 
> > $a)$ -  different variants one 2 one = normal neural net
> > MtM many inputs to many outputs 
> > MtO 
> > OtM 
> $b)$ - weightings $= a_0 \times (w_0)^t$
> $c)$ - LIMITATIONS
> Inference is slow, sequential computation limits opportunity for parallelisation
> No look ahead
> Long-term memory 
>  Weights either vanish or blow up 

---

## Recurrent Neural Net 

USES past results 

![[Recurrent NN Variants.png]]