# TODO
---
> [!info]+ File Details
> Includes information about this (genus:: Note) from [Year::2]. Contains details on when this was created, what module the note belongs to.
> > *Date :*  01-05-2025
> > *Resources :*

---
> [!abstract]+ Contents
> List of todos by topic
> > [[#ML]]
> [[#Algorithms & Complexity]]
> [[#]]
> [[#]]
> [[#]]

---

# ML

▼ [Machine Learning](https://lectures.circuit10.uk/#) [Y2425-CM22009-LecaMachineLearning-week31](https://uniofbath.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=e1d989b3-7bd2-4e08-be98-b2cd00ca3221) 16:15, Mon, 28 Apr 2025

1. Introduction to Bayesian machine learning
2. Historical context of Bayesian inference
3. Importance of capturing uncertainty in predictions
4. Case study: Space Shuttle Challenger disaster
5. Role of decision making in statistics and machine learning
6. Separation of probabilistic inference from decision making
7. Overview of Bayesian inference
8. Bayes' theorem and its components
9. Prior distributions and their significance
10. Posterior distributions and the process of updating beliefs
11. Normalization factor in Bayesian inference
12. Approximation techniques for Bayesian calculations
13. Overview of variational inference and Markov chain Monte Carlo
14. Advantages of Bayesian approaches:
    - Probabilistic predictions
    - Handling of big and small data
    - Incorporating desired properties through priors
    - Qualifying informative predictions
    - Robustness through marginalization
    - Implicit implementation of Occam's Razor
15. Sparse prior distributions in Bayesian models
16. Example: Gene expression prediction of leukaemia
17. Image decomposition demonstration using Bayesian techniques
18. Comparison of Bayesian and greedy algorithms
19. Algorithm showcasing the benefits of Bayesian prior in model selection
20. Convergence of Bayesian optimization and error reduction

Friday 25 Apr 2025

▼ [Machine Learning](https://lectures.circuit10.uk/#) [Y2425-CM22009-LecbMachineLearning-week30](https://uniofbath.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=855d51cd-2ed2-4531-b8e1-b2ca0056ccbc) 09:15, Fri, 25 Apr 2025

1. Announcements and feedback overview
2. Cross-entropy and delta function explanation
3. Overview of brain-inspired models
4. Memorization of equations for exams
5. Supervised vs. unsupervised learning classification
6. Features and labels in supervised learning
7. Loss function definition and optimization
8. Linear regression loss function
9. Decision boundaries in shallow neural networks
10. Activation functions: Rectified Linear Unit (ReLU), sigmoid, hyperbolic tangent
11. Expressiveness of neural networks and hidden units
12. Approximation guarantees in neural networks
13. Shallow vs. deep neural networks
14. Depth efficiency and representation of functions
15. Hierarchical structures in deep neural networks
16. Gradient descent optimization
17. Stochastic gradient descent
18. Momentum in gradient updates
19. Adam optimizer and its advantages
20. Loss functions: L2 squared loss, probabilistic interpretations
21. Classifier outputs: Sigmoid and softmax functions
22. Additional questions and Q&A session

Friday 4 Apr 2025

▼ [Machine Learning](https://lectures.circuit10.uk/#) [Y2425-CM22009-LecbMachineLearning-week27](https://uniofbath.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=d5011a18-7315-4404-91bf-b2b50056ccaf) 09:15, Fri, 4 Apr 2025

1. Definition of identity shortcut in ResNet
2. Benefits and drawbacks of skip connections in deep learning
3. Overview of regularization techniques
4. Implicit regularization techniques
    - Data augmentation
    - Early stopping
    - Dropout layers
5. Explicit regularization techniques
    - L1 regularization (Lasso)
    - L2 regularization (Ridge)
    - Elastic Net regularization
6. Importance of generalization in machine learning
7. Impact of training data and validation data on model performance
8. Loss curves and overfitting
9. Techniques for identifying early stopping criteria
10. Checkpointing in model training
11. Types of data augmentation for images, audio, and text
12. Risks and downsides of data augmentation
13. Application of dropout layers in neural networks
14. Challenges associated with dropout layers
15. Explanation of loss functions and optimization
16. Combining multiple regularization techniques
17. Exam structure and subjects covered
18. Resources for machine learning operations and deployment
19. Upcoming guest lectures and exam practice sessions

Monday 31 Mar 2025

▼ [Machine Learning](https://lectures.circuit10.uk/#) [Y2425-CM22009-LecaMachineLearning-week27](https://uniofbath.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=015667e7-49de-4617-8356-b2b100ca32a1) 16:15, Mon, 31 Mar 2025

1. Introduction to Natural Language Processing (NLP)
2. Definition and importance of language understanding
3. Language as an evolutionary advantage
4. The complexity of language and its relation to culture and context
5. Components of NLP: linguistics, artificial intelligence, mathematical logic
6. Natural Language Understanding (NLU) and Natural Language Generation (NLG)
7. Overview of chatbots and language models (e.g., ChatGPT)
8. The hard problem of AI and language understanding (AI-hard)
9. Demonstration of language understanding using idiomatic expressions
10. Challenges in traditional NLP methods (e.g., rule-based systems)
11. Evolution of NLP methods post-World War II
12. Statistical methods in NLP from the 1990s
13. Introduction of neural networks and transformers in NLP
14. Overview of traditional NLP systems: sentiment analysis and rule-writing
15. Back-translation and its role in assessing translation quality
16. The impact of masked language modeling on NLP
17. Language model pre-training and fine-tuning
18. Emergence of reasoning in language models
19. Examples of language models and their capabilities
20. Hallucination in language models and implications
21. The significance of model size and scale on performance
22. Techniques for improving language model performance (e.g., chain-of-thought prompting)
23. Self-consistency prompting for increased accuracy
24. Using language models for programming and problem-solving
25. Comparison of traditional NLP with data-driven methods
26. Deep learning models and the impact of group distributional preference optimization
27. Ethical considerations and potential risks of advanced language models
28. Recommended usage guidelines for leveraging language models in industry

Friday 28 Mar 2025

▼ [Machine Learning](https://lectures.circuit10.uk/#) [Y2425-CM22009-LecbMachineLearning-week26](https://uniofbath.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=7d5b25e0-827c-42bc-a6fa-b2ae00674857) 08:15, Fri, 28 Mar 2025

1. Course level survey reminder
2. Overview of Convolutional Neural Networks (CNN)
3. Dilation rates in convolutions
4. Understanding convolution operations under the hood
5. Conceptual representation of convolutions on images
6. Common mistakes in convolution outputs
7. Non-dilated vs. dilated convolution filters
8. Benefits of dilation in CNNs
9. Mathematical representation of CNN layers
10. Shared weights in convolutional layers
11. Residual Neural Networks (ResNet) introduction
12. Addressing vanishing and exploding gradient problems
13. Identifying abnormal gradient distributions
14. Analyzing learning curves to detect gradient issues
15. Irregular outputs as indicators of vanishing gradients
16. Comparison of activation functions: Sigmoid vs. ReLU
17. Impact of activation functions on gradient flow
18. Skip connections vs. residual connections
19. Computational costs and interpretability in ResNet
20. Identity shortcuts in ResNet and their implications
21. Drawbacks of residual blocks in neural networks
22. Review of lecture content and upcoming topics.

---


# Algorithms & Complexity

Tuesday 29 Apr 2025

▼ [Algorithms and Complexity](https://lectures.circuit10.uk/#) [CM22008 Recap 1: automata and languages](https://uniofbath.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=87e5a1d9-abcc-4ad6-839b-b2ce00676f0c) 10:15, Tue, 29 Apr 2025

1. Overview of semester one material
2. Examination format in Moodle
3. Deterministic Finite Automata (DFA) and Non-deterministic Finite Automata (NFA)
4. Regular languages and context-free languages
5. Pumping lemma for regular languages
6. Context-free grammars and pushdown automata equivalence
7. Turing machines and semi-decidable languages
8. Pumping lemma for context-free languages
9. Determining non-regular languages using pumping lemma
10. Implementation level description of Turing machines
11. Complexity class P and NP
12. Example problems: DFA construction and language acceptance
13. Complement of a language in DFA
14. Subword definition and its relation to context-free grammars
15. Church-Turing thesis
16. Recognition of languages through Turing machines
17. Checking divisibility of A's in a word using Turing machines

Thursday 24 Apr 2025

▼ [Algorithms and Complexity](https://lectures.circuit10.uk/#) [CM22008 2.18: diff](https://uniofbath.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=eceeb436-ab09-4b6b-918d-b2c900eb3e9f) 18:15, Thu, 24 Apr 2025

1. Overview of the lecture and schedule for upcoming recaps
2. Introduction to the diff utility in Unix for computing file differences
3. Definition of edits: insertions and deletions
4. Minimal edit distance problem: transforming file A to file B
5. Length of edit sequence: number of deletions and insertions
6. Examples of edit sequences and their lengths
7. Analysis of common subsequences and their importance
8. Definition of subsequences and examples
9. Longest common subsequence problem (LCS) explained
10. Recursive definition for computing LCS
11. Issues with naive recursive implementation
12. Dynamic programming approach for LCS
13. Bellman equation for LCS length
14. Complexity analysis of LCS dynamic programming solution
15. Comparison of dynamic programming vs. Dijkstra's algorithm for shortest paths
16. Grid representation of edits as a shortest path problem
17. Dijkstra's algorithm application in the context of edit distance
18. Explanation of bucket queue implementation for Dijkstra's algorithm
19. Complexity of Dijkstra's algorithm in relation to edit distance
20. Myers diff algorithm overview and its efficiency
21. Introduction to patience diff algorithm for chunking code
22. Conclusion on efficient problem-solving strategies in algorithm design
23. Recommendations for further reading on diff algorithms and related topics