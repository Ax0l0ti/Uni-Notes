# Reinforcement Learning
---
> [!info]+ Module Details
> Contains details on this (genus:: Module) from [Year::3]: Module Code, Teacher tags and Resources 
> > *Module :* (ModCode :: CM32032)
> > *Teacher*: 
> > *Resources :* [Bath Catalogue](https://www.bath.ac.uk/catalogues/2025-2026/cm/CM32032.html) [Reinforcement Learning An Introduction 2nd ed](https://0-lucas.github.io/digital-garden/99.-Books/Reinforcement-Learning,-Second-Edition-_-An-Introduction----Richard-S_-Sutton;-Andrew-G_-Barto-.pdf) [Reinforcement Learning: An Introduction | MIT Press eBooks | IEEE Xplore](https://ieeexplore-ieee-org.ezproxy1.bath.ac.uk/book/6267343)

---
> [!abstract]+ Contents
> 
> Module Sub-Topics
> > [[Markov Decision Processes]]
> [[Dynamic Programming]]
> [[Monte Carlo Methods]]
> [[Temporal Difference Learning]]
> [[Deep RL]]

---
### Coursework 100% vs 0% Examined
- Project output Group (CWPG 100%)

---
### Course Description

> [!info]+ Course Description
> Course Description copied from link 
> 
|   | Content  |
|---|---|
|**Learning Outcomes:**|On completion of the unit, the students will be able to: 1. describe how reinforcement learning problems differ from supervised learning problems such as regression and classification; 2. formulate suitable real-world problems as reinforcement learning problems by defining a state space, an action space, and a reward function appropriate for the context; 3. apply a range of basic solution methods to reinforcement learning problems; 4. appreciate the difficulties encountered in solving large, complex reinforcement learning problems in practice.|
|**Synopsis:**|You will explore reinforcement learning as a problem-solving method, and how it differs from other fundamental techniques such as supervised and unsupervised learning. You will learn to formulate real-world problems as reinforcement learning problems, to apply basic solution methods, and to appreciate the difficulties involved in large, complex reinforcement learning problems in practice.|
|**Content:**|Topics covered normally include: dynamic programming, Monte Carlo methods, temporal-difference algorithms, integration of planning and learning, value function approximation, and policy gradient methods.|


---

## Semester 1 

In the first half of Semester 1, we will cover the following topics:

1. The reinforcement learning problem.
2. Markov decision processes.
3. Dynamic programming methods.
4. Monte-Carlo methods.
5. Temporal-difference methods.
6. Planning andÂ n-step methods.

In the second half of Semester 1, we will cover the following topics:

1. Function approximation and generalisation in reinforcement learning.
2. Linear function approximated methods.
3. Deep reinforcement learning methods.
4. Policy-gradient methods.
5. Actor-critic methods.

## Semester 2